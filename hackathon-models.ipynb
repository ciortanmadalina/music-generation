{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import converter, instrument, note, chord, midi\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import newaxis\n",
    "\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.collections\n",
    "from matplotlib import gridspec\n",
    "\n",
    "import datetime\n",
    "from tqdm import *\n",
    "from datetime import *\n",
    "\n",
    "import keras\n",
    "from keras.applications import *\n",
    "import lightgbm as lgbm\n",
    "import os\n",
    "from scipy import ndimage\n",
    "from scipy import misc\n",
    "from scipy import signal\n",
    "import cv2\n",
    "plt.ion()\n",
    "plt.show()\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input, Dense, Lambda, Layer,Flatten,TimeDistributed, BatchNormalization, GlobalMaxPooling1D\n",
    "from keras.layers import Conv2D,Conv1D, MaxPooling1D, MaxPooling2D,UpSampling2D, concatenate, Dropout,Conv2DTranspose, LSTM\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Activation\n",
    "from music21 import instrument, note, stream, chord\n",
    "import shutil\n",
    "import collections\n",
    "from collections import *\n",
    "from keras import optimizers\n",
    "import tensorflow as tf\n",
    "from IPython.display import clear_output\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from os.path import isfile, join\n",
    "from sklearn import preprocessing\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score, classification_report,confusion_matrix\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from skimage import morphology\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from skimage import filters\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage as ndi\n",
    "from music21 import corpus\n",
    "from keras.layers import Concatenate, TimeDistributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from scipy.stats import entropy\n",
    "\n",
    "def subsongStats(subsong):\n",
    "    vs = np.argmax(subsong, axis=1)\n",
    "    e = entropy([list(vs).count(x) for x in set(vs)]) # note entropy\n",
    "\n",
    "    seq = []\n",
    "    last = vs[0]\n",
    "    count = 0\n",
    "    for i in range(len(vs)):\n",
    "        if last != vs[i]:\n",
    "            seq.append(count)\n",
    "            last = vs[i]\n",
    "            count = 1\n",
    "        else:\n",
    "            count = count + 1\n",
    "    \n",
    "    seq.append(count)\n",
    "    if len(seq) != 0:\n",
    "        m = np.median(seq)\n",
    "        if (len(seq) == 0):\n",
    "            print(vs, seq, e, m)\n",
    "        r = seq.count(1)/len(seq)\n",
    "    else:\n",
    "        m = 0\n",
    "        r = 0\n",
    "    \n",
    "    return vs, e, m, r\n",
    "\n",
    "\n",
    "def predictOneBitstream(seed, threshold=0.99, length=128):\n",
    "    inp = seed\n",
    "    for i in range(length):\n",
    "        p = model.predict(inp[:,-lookback:,:])\n",
    "        p = cleanpred(p[0])\n",
    "        inp = np.concatenate([inp,p[newaxis,newaxis,:]], axis=1)\n",
    "\n",
    "    outp = inp[:,lookback:,:] # remove the seed\n",
    "    return outp\n",
    "\n",
    "def predictOneStream(seed, threshold=0.99):\n",
    "    outp =predictOneBitstream(seed, threshold)\n",
    "\n",
    "#     pp = predictOneBitstream(nn_inout2[i:i+1,:,:])\n",
    "    print(outp.shape)\n",
    "    v, e, m, p = subsongStats(outp[0]) \n",
    "    print(e,m,p)    \n",
    "    \n",
    "    \n",
    "    output_notes = []\n",
    "    s = stream.Stream()\n",
    "    for i in range(len(outp[0])):\n",
    "        n = predbitfieldtonote(outp[0,i],threshold=threshold)\n",
    "        s.append(n)\n",
    "    return s\n",
    "\n",
    "class PlotLosses(keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        self.initVars()\n",
    "    \n",
    "    def initVars(self):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = [] # self validation\n",
    "        self.fig = plt.figure()\n",
    "        self.logs = []\n",
    "        self.lr = []\n",
    "        self.e = []\n",
    "        self.m = []\n",
    "        self.p = []\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        ;\n",
    "#         self.initVars()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        curloss = logs.get('loss')\n",
    "        self.losses.append(curloss)\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.logs.append(logs)\n",
    "        self.i = self.i+1\n",
    "        \n",
    "        if self.i%5 != 0:\n",
    "            return\n",
    "        self.evaluateRandomSample()\n",
    "        clear_output(wait=True)\n",
    "        plt.figure(figsize=(12,12))\n",
    "        ax = plt.subplot(221)\n",
    "        self.plotLosses(ax)\n",
    "        ax = plt.subplot(222)\n",
    "        ax.plot(self.e)\n",
    "        plt.title('entropy of note distribution')\n",
    "        ax = plt.subplot(223)\n",
    "        plt.title('median of repetition length')\n",
    "        ax.plot(self.m)\n",
    "        ax = plt.subplot(224)\n",
    "        plt.title('percentage of repetition 1')\n",
    "        ax.plot(self.p)\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "    def evaluateRandomSample(self):\n",
    "        i = random.randint(1, nn_inout2.shape[0])\n",
    "        _, e, m, p = subsongStats(predictOneBitstream(nn_inout2[i:i+1,:,:])[0]) \n",
    "        self.e.append(e)\n",
    "        self.m.append(m)\n",
    "        self.p.append(p)\n",
    "    \n",
    "    def plotLosses(self, ax):\n",
    "        plt.plot(np.arange(len(self.losses)), self.losses, label=\"train loss\")\n",
    "        plt.plot(np.arange(len(self.val_losses)), self.val_losses, label=\"val loss\")\n",
    "        # ax.set_yscale(\"log\", nonposy='clip')\n",
    "        plt.legend()\n",
    "        \n",
    "basicLossPlot = PlotLosses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from IPython.display import clear_output\n",
    "\n",
    "# class PlotLosses(keras.callbacks.Callback):\n",
    "#     def __init__(self):\n",
    "#         self.initVars()\n",
    "    \n",
    "#     def initVars(self):\n",
    "#         self.i = 0\n",
    "#         self.x = []\n",
    "#         self.losses = []\n",
    "#         self.val_losses = [] # self validation\n",
    "#         self.fig = plt.figure()\n",
    "#         self.logs = []\n",
    "#         self.lr = []\n",
    "        \n",
    "#     def on_train_begin(self, logs={}):\n",
    "#         ;\n",
    "# #         self.initVars()\n",
    "\n",
    "#     def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "#         curloss = logs.get('loss')\n",
    "#         self.losses.append(curloss)\n",
    "#         self.val_losses.append(logs.get('val_loss'))\n",
    "#         self.logs.append(logs)\n",
    "#         self.i = self.i+1\n",
    "        \n",
    "#         if self.i%5 != 0:\n",
    "#             return\n",
    "#         clear_output(wait=True)\n",
    "#         plt.figure(figsize=(6,6))\n",
    "#         ax = plt.figure(111)\n",
    "#         self.plotLosses(ax)\n",
    "#         plt.show()\n",
    "\n",
    "#     def plotLosses(self, ax):\n",
    "#         plt.plot(np.arange(len(self.losses)), self.losses, label=\"train loss\")\n",
    "#         plt.plot(np.arange(len(self.val_losses)), self.val_losses, label=\"val loss\")\n",
    "#         # ax.set_yscale(\"log\", nonposy='clip')\n",
    "#         plt.legend()\n",
    "        \n",
    "# basicLossPlot = PlotLosses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printChord(c):\n",
    "    print([x.nameWithOctave for x in c.pitches])\n",
    "    print('PitchedCommonName: %s, root %s, intervalVector %s, normalOrder % ' % \n",
    "          (c.pitchedCommonName, c.root(), c.intervalVector, c.normalOrder))\n",
    "    c.show()\n",
    "    \n",
    "def printNote(f):\n",
    "    \n",
    "    if f.name == 'rest':\n",
    "        st = f.name\n",
    "    else:\n",
    "        st = f.name + str(f.step) + ' ' + str(f.octave) + ' ' +  str(f.pitch.french) + ' ' + str(f.pitch) + ' ' + str(f.pitch.frequency)\n",
    "        if f.pitch.accidental:\n",
    "            st = st + ' ' + f.pitch.accidental.name + ' -extra semi-tones:' + f.pitch.accidental.alter\n",
    "#     print(st)\n",
    "    f.addLyric(st)\n",
    "    return f.show()\n",
    "\n",
    "def printPitch(p):\n",
    "    print(p, p.nameWithOctave, p.french, p.octave, p.frequency)\n",
    "    if p.accidental:\n",
    "        print(p.accidental, p.accidental.name, '-extra semi-tones: ',p.accidental.alter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readSong(s, maxtracks = -1, chordify = False, gatherRests=True, qlMult=4, qlMin=1, qlMax=16):\n",
    "    # maxtracks=-1 returns 1 track with all elements combined one after the other, otherwise returns top X tracks\n",
    "    # chordify toggles putting all parts together\n",
    "    # gatherRests combines all rests into 1 (no more than 1 contiguous rest)\n",
    "    # qlMult multiplies quarterLengths of notes/rests by that factor\n",
    "    # qlMin/qlMax restricts note length\n",
    "    \n",
    "#     notes = np.zeros((0,n_vocab+(1+qlMax-qlMin)))\n",
    "    notes = []\n",
    "    \n",
    "    if chordify == False:\n",
    "        parts = s.parts\n",
    "    else:\n",
    "        parts = [s.chordify()]\n",
    "    \n",
    "    lastwasrest = False\n",
    "    for p in parts:\n",
    "        for element in s.recurse().notesAndRests:\n",
    "            duration = int(element.duration.quarterLength *qlMult)\n",
    "            duration = min(qlMax,max(qlMin,duration)) # don't want longer than whole or shorter than 16th\n",
    "            ch = ''\n",
    "            newnote = np.zeros(n_vocab+n_duration)\n",
    "            \n",
    "            if isinstance(element, note.Rest):\n",
    "                nn = 0\n",
    "                if lastwasrest == True and gatherRests == True:\n",
    "                    continue # no need for multiple rests in this scenario\n",
    "                lastwasrest = True\n",
    "            elif isinstance(element, note.Note):\n",
    "                lastwasrest = False\n",
    "                nn = int(element.pitch.midi)+0\n",
    "                newnote[nn] = 1\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                lastwasrest = False\n",
    "                for xxx in element.pitches:\n",
    "                    newnote[xxx.midi] = 1\n",
    "\n",
    "            newnote[n_vocab+int(duration)-1] = 1\n",
    "\n",
    "            notes.append(newnote)\n",
    "#             notes = np.concatenate([notes, newnote[newaxis,:]], axis=0)\n",
    "            \n",
    "    return np.stack(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequence_length = 100\n",
    "n_vocab = 128\n",
    "n_duration = 16\n",
    "lookback = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanpred(pred, threshold=0.8):\n",
    "    t = np.max(pred[:n_vocab])*threshold\n",
    "    du = np.argmax(pred[n_vocab:])\n",
    "    \n",
    "#     print(np.where(pred[:n_vocab] > t))\n",
    "    p2 = np.zeros(pred.shape)\n",
    "    p2[np.where(pred[:n_vocab] > t)] = 1\n",
    "    p2[n_vocab+du] = 1\n",
    "    return p2\n",
    "\n",
    "def predbitfieldtonote(pred, threshold=0.8):\n",
    "    t = np.max(pred[:n_vocab])*threshold\n",
    "    du = np.argmax(pred[n_vocab:])\n",
    "    if np.argmax(pred)==0:\n",
    "        n = note.Rest()\n",
    "        n.duration.quarterLength = (du+1)/4\n",
    "    else:\n",
    "        nns = []\n",
    "        for pp in np.where(pred[:n_vocab] > t)[0]:\n",
    "            nn = note.Note()\n",
    "            nn.pitch.midi = pp\n",
    "            nns.append(nn)\n",
    "        n = chord.Chord(nns)\n",
    "        n.duration.quarterLength = (du+1)/4\n",
    "    return n\n",
    "\n",
    "def predtostream(pred):\n",
    "    s = stream.Stream()\n",
    "    for i in range(len(pred)):\n",
    "        n = predbitfieldtonote(pred[i])\n",
    "        s.append(n)\n",
    "    return s\n",
    "\n",
    "\n",
    "def writePrediction(inp, lookback=lookback):\n",
    "    outp = inp[:,lookback:,:] # remove the seed\n",
    "\n",
    "    output_notes = []\n",
    "    s = stream.Stream()\n",
    "    for i in range(len(outp[0])):\n",
    "        n = predbitfieldtonote(outp[0,i],threshold=thresh)\n",
    "        s.append(n)\n",
    "    filename = 'output/test_output' + datetime.now().strftime(\"%Y%m%d%H%M%S\") + '.mid'\n",
    "    print('writing prediction size %s to file %s ' % (outp.shape, filename))\n",
    "    s.write('midi', fp=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Bach from corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('data/bachNoCordify1.npy'):\n",
    "    nn_inout = np.load('data/bachNoCordify1.npy')\n",
    "else:\n",
    "    songs = []\n",
    "    for i in tqdm(corpus.getComposer('bach', 'mxl')):\n",
    "        s = corpus.parse(i)\n",
    "        songs.append(readSong(s, maxtracks = -1, chordify = False, gatherRests=False, qlMult=4, qlMin=1, qlMax=16))\n",
    "    nn_inout = np.vstack(songs)\n",
    "    np.save('data/bachNoCordify1.npy', nn_inout)\n",
    "    \n",
    "nn_inout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if os.path.isfile('data/beethovenNoCordify1.npy'):\n",
    "    nn_inout = np.load('data/beethovenNoCordify1.npy')\n",
    "else:\n",
    "    songs = []\n",
    "    for i in tqdm(corpus.getComposer('beethoven', 'mxl')):\n",
    "        s = corpus.parse(i)\n",
    "        songs.append(readSong(s, maxtracks = -1, chordify = False, gatherRests=False, qlMult=4, qlMin=1, qlMax=16))\n",
    "    nn_inout = np.vstack(songs)\n",
    "    np.save('data/beethovenNoCordify1.npy', nn_inout)\n",
    "    \n",
    "nn_inout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('data/beethovenCordify1.npy'):\n",
    "    nn_inout = np.load('data/beethovenCordify1.npy')\n",
    "else:\n",
    "    songs = []\n",
    "    for i in tqdm(corpus.getComposer('beethoven', 'mxl')):\n",
    "        s = corpus.parse(i)\n",
    "        songs.append(readSong(s, maxtracks = -1, chordify = True, gatherRests=False, qlMult=4, qlMin=1, qlMax=16))\n",
    "    nn_inout = np.vstack(songs)\n",
    "    np.save('data/beethovenCordify1.npy', nn_inout)\n",
    "    \n",
    "nn_inout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "if os.path.isfile('data/4cCordify.npy'):\n",
    "    nn_inout = np.load('data/4cCordify.npy')\n",
    "else:\n",
    "    songs = []\n",
    "    for i in tqdm(corpus.getComposer('verdi', 'mxl')):\n",
    "        s = corpus.parse(i)\n",
    "        songs.append(readSong(s, maxtracks = -1, chordify = True, gatherRests=False, qlMult=4, qlMin=1, qlMax=16))\n",
    "        \n",
    "    for i in tqdm(corpus.getComposer('bach', 'mxl')):\n",
    "        s = corpus.parse(i)\n",
    "        songs.append(readSong(s, maxtracks = -1, chordify = True, gatherRests=False, qlMult=4, qlMin=1, qlMax=16))\n",
    "        \n",
    "    for i in tqdm(corpus.getComposer('mozart', 'mxl')):\n",
    "        s = corpus.parse(i)\n",
    "        songs.append(readSong(s, maxtracks = -1, chordify = True, gatherRests=False, qlMult=4, qlMin=1, qlMax=16))\n",
    "        \n",
    "    for i in tqdm(corpus.getComposer('beethoven', 'mxl')):\n",
    "        s = corpus.parse(i)\n",
    "        songs.append(readSong(s, maxtracks = -1, chordify = True, gatherRests=False, qlMult=4, qlMin=1, qlMax=16))\n",
    "    nn_inout = np.vstack(songs)\n",
    "    np.save('data/4cCordify.npy', nn_inout)\n",
    "    \n",
    "nn_inout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if os.path.isfile('data/4cCordify.npy'):\n",
    "    nn_inout = np.load('data/4cCordify.npy')\n",
    "else:\n",
    "    songs = []\n",
    "    for i in tqdm(corpus.getComposer('verdi', 'mxl')):\n",
    "        s = corpus.parse(i)\n",
    "#         print('.', end='')\n",
    "        songs.append(readSong(s, maxtracks = -1, chordify = True, gatherRests=False, qlMult=4, qlMin=1, qlMax=16))\n",
    "        \n",
    "    for i in tqdm(corpus.getComposer('bach', 'mxl')):\n",
    "#         print('.', end='')\n",
    "        s = corpus.parse(i)\n",
    "        songs.append(readSong(s, maxtracks = -1, chordify = True, gatherRests=False, qlMult=4, qlMin=1, qlMax=16))\n",
    "        \n",
    "    for i in tqdm(corpus.getComposer('mozart', 'mxl')):\n",
    "#         print('.', end='')\n",
    "        s = corpus.parse(i)\n",
    "        songs.append(readSong(s, maxtracks = -1, chordify = True, gatherRests=False, qlMult=4, qlMin=1, qlMax=16))\n",
    "        \n",
    "#     for i in tqdm(corpus.getComposer('beethoven', 'mxl')):\n",
    "#         print('.', end='')\n",
    "#         s = corpus.parse(i)\n",
    "#         songs.append(readSong(s, maxtracks = -1, chordify = True, gatherRests=False, qlMult=4, qlMin=1, qlMax=16))\n",
    "    nn_inout = np.vstack(songs)\n",
    "    np.save('data/4cCordify.npy', nn_inout)\n",
    "    \n",
    "nn_inout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#palestrina\n",
    "\n",
    "if os.path.isfile('data/2c.npy'):\n",
    "    nn_inout = np.load('data/2c.npy')\n",
    "else:\n",
    "    songs = []\n",
    "    for i in tqdm(corpus.getComposer('palestrina', 'mxl')):\n",
    "        s = corpus.parse(i)\n",
    "        songs.append(readSong(s, maxtracks = -1, chordify = False, gatherRests=False, qlMult=4, qlMin=1, qlMax=16))\n",
    "        \n",
    "    for i in tqdm(corpus.getComposer('bach', 'mxl')):\n",
    "        s = corpus.parse(i)\n",
    "        songs.append(readSong(s, maxtracks = -1, chordify = False, gatherRests=False, qlMult=4, qlMin=1, qlMax=16))\n",
    "        \n",
    "\n",
    "    nn_inout = np.vstack(songs)\n",
    "    np.save('data/2c.npy', nn_inout)\n",
    "    \n",
    "nn_inout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "if os.path.isfile('data/4c.npy'):\n",
    "    nn_inout = np.load('data/4c.npy')\n",
    "else:\n",
    "    songs = []\n",
    "    for i in tqdm(corpus.getComposer('verdi', 'mxl')):\n",
    "        s = corpus.parse(i)\n",
    "        songs.append(readSong(s, maxtracks = -1, chordify = False, gatherRests=False, qlMult=4, qlMin=1, qlMax=16))\n",
    "        \n",
    "    for i in tqdm(corpus.getComposer('bach', 'mxl')):\n",
    "        s = corpus.parse(i)\n",
    "        songs.append(readSong(s, maxtracks = -1, chordify = False, gatherRests=False, qlMult=4, qlMin=1, qlMax=16))\n",
    "        \n",
    "    for i in tqdm(corpus.getComposer('mozart', 'mxl')):\n",
    "        s = corpus.parse(i)\n",
    "        songs.append(readSong(s, maxtracks = -1, chordify = False, gatherRests=False, qlMult=4, qlMin=1, qlMax=16))\n",
    "        \n",
    "    for i in tqdm(corpus.getComposer('beethoven', 'mxl')):\n",
    "        s = corpus.parse(i)\n",
    "        songs.append(readSong(s, maxtracks = -1, chordify = False, gatherRests=False, qlMult=4, qlMin=1, qlMax=16))\n",
    "    nn_inout = np.vstack(songs)\n",
    "    np.save('data/4c.npy', nn_inout)\n",
    "    \n",
    "nn_inout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read files from folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folderName = \"data/clean_midi/*/*.mid\"\n",
    "len(glob.glob(folderName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# folderName = \"data/*.mid\"\n",
    "folderName = \"data/clean_midi/*/*.mid\"\n",
    "# fileName = 'data/cleanData.npy'\n",
    "# fileName = 'data/cleanData1000000.npy'\n",
    "fileName = 'data/cleanData5000000.npy'\n",
    "if os.path.isfile(fileName):\n",
    "    nn_inout = np.load(fileName)\n",
    "else:\n",
    "    songs = []\n",
    "    for file in tqdm(glob.glob(folderName)[:300]):\n",
    "        try:\n",
    "            midiP = converter.parse(file)\n",
    "            songs.append(readSong(midiP, maxtracks = -1, chordify = False, gatherRests=False, qlMult=4, qlMin=1, qlMax=16))\n",
    "        except Exception:\n",
    "            pass\n",
    "    nn_inout = np.vstack(songs)\n",
    "    np.save(fileName, nn_inout)\n",
    "nn_inout.shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nn_inout = nn_inout[:5000000]\n",
    "# np.save('data/cleanData5000000.npy', nn_inout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 : Predict 1 note at a time model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = Input(shape=(lookback,nn_inout.shape[1],))\n",
    "x = LSTM(256, return_sequences=True)(inp)\n",
    "x = Dropout(0.3)(x)\n",
    "x = LSTM(512, return_sequences=True)(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = LSTM(256)(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(nn_inout.shape[1])(x)\n",
    "a1 = Activation('sigmoid')(Lambda(lambda z : z[:,:n_vocab])(x)) # notes\n",
    "a2 = Activation('softmax')(Lambda(lambda z : z[:,n_vocab:])(x)) # duration\n",
    "x= concatenate([a1,a2])\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "\n",
    "learning_rate = 0.1\n",
    "decay_rate = learning_rate / epochs\n",
    "momentum = 0.8\n",
    "sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "sgd = SGD(lr=learning_rate, nesterov=False)\n",
    "# model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001))\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "# model.compile(loss='binary_crossentropy', optimizer=sgd)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('all data', nn_inout.shape)\n",
    "print('lookback', lookback)\n",
    "print('train', nn_inout[:-lookback].shape)\n",
    "print('to predict', nn_inout[lookback:].shape)\n",
    "\n",
    "# Add '0' at the end to make sure it fits blocks of 32\n",
    "nn_inout2 = np.pad(nn_inout,((0,lookback-nn_inout.shape[0]%lookback),(0,0)), 'constant', constant_values=(0))\n",
    "nn_inout2.shape\n",
    "nn_inout2 = nn_inout2.reshape(-1, lookback, 144)\n",
    "nn_inout2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "basicLossPlot = PlotLosses()\n",
    "model.fit(nn_inout2[:-1,:,:], nn_inout2[1:,0,:], epochs=200, batch_size=512, callbacks=[basicLossPlot])\n",
    "# model.save_weights('weights-improvement-p3{datetime.now().strftime(\"%Y%m%d%H%M%S\")}.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = random.randint(1,nn_inout2.shape[0])\n",
    "# t\n",
    "s = predtostream(nn_inout2[t]) # stream of 32 notes\n",
    "# s\n",
    "\n",
    "n = predbitfieldtonote(model.predict(nn_inout2[t:t+1,:,:])[0])\n",
    "n.color='red'\n",
    "s.append(n)\n",
    "c = predbitfieldtonote(nn_inout2[t+1,0,:])\n",
    "c.color='green'\n",
    "s.append(c)\n",
    "s.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn_inout2[2].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict a song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thresh = 0.8\n",
    "\n",
    "# create a seed and predict stuff\n",
    "t = random.randint(0,nn_inout2.shape[0]-1)\n",
    "seed = nn_inout2[t:t+1,:,:]\n",
    "print('seed size : ', seed.shape)\n",
    "\n",
    "inp = seed\n",
    "# inp.shape\n",
    "# inp[:,-lookback:,:].shape\n",
    "for i in range(128):\n",
    "    p = model.predict(inp[:,-lookback:,:])\n",
    "    p = cleanpred(p[0])\n",
    "    inp = np.concatenate([inp,p[newaxis,newaxis,:]], axis=1)\n",
    "    print('.', end='')\n",
    "    \n",
    "print('Total size ', inp.shape)    \n",
    "s = stream.Stream()\n",
    "for i in range(len(inp[0])):\n",
    "    n = predbitfieldtonote(inp[0,i],threshold=thresh)\n",
    "    if i < lookback:\n",
    "        n.color='blue'\n",
    "    s.append(n)\n",
    "s.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write predicted song to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writePrediction(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 : Predict 32 notes sequence model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binary_crossentropy1(y_true, y_pred):\n",
    "    print('>', K.mean(K.binary_crossentropy(y_true, y_pred), axis=-1))\n",
    "    return K.mean(K.binary_crossentropy(y_true, y_pred), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(lookback,nn_inout.shape[1],))\n",
    "x = LSTM(256, return_sequences=True)(inp)\n",
    "x = Dropout(0.3)(x)\n",
    "x = LSTM(512, return_sequences=True)(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = LSTM(256, return_sequences=True)(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = TimeDistributed(Dense(nn_inout.shape[1]))(x)\n",
    "a1 = Activation('sigmoid')(Lambda(lambda z : z[:,:,:n_vocab])(x)) # notes\n",
    "a2 = Activation('softmax')(Lambda(lambda z : z[:,:,n_vocab:])(x)) # duration\n",
    "x= concatenate([a1,a2])\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop')\n",
    "# model.compile(loss='kullback_leibler_divergence', optimizer='rmsprop')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add '0' at the end to make sure it fits blocks of 32\n",
    "nn_inout2 = np.pad(nn_inout,((0,lookback-nn_inout.shape[0]%lookback),(0,0)), 'constant', constant_values=(0))\n",
    "nn_inout2.shape\n",
    "nn_inout2 = nn_inout2.reshape(-1, lookback, 144)\n",
    "nn_inout2.shape\n",
    "nn_inout2 = np.concatenate([nn_inout2[:-1,:,:], nn_inout2[1:, 0:1, :]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "basicLossPlot = PlotLosses()\n",
    "model.fit(nn_inout2[:-1,:32,:], nn_inout2[:-1,1:,:], epochs=200, batch_size=256, callbacks=[basicLossPlot])\n",
    "# model.save_weights('weights-improvement-p3{datetime.now().strftime(\"%Y%m%d%H%M%S\")}.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict one sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = random.randint(1,nn_inout2.shape[0])\n",
    "s = predtostream(nn_inout2[t])\n",
    "print('before green ', len(s.notes), nn_inout2[t].shape)\n",
    "c = predbitfieldtonote(nn_inout2[t+1,0,:])\n",
    "c.color='green'\n",
    "s.append(c)\n",
    "print('green ', len(s.notes))\n",
    "\n",
    "x = model.predict(nn_inout2[t:t+1,:lookback,:])\n",
    "x.shape\n",
    "for i in range(x.shape[1]):\n",
    "    n = predbitfieldtonote(x[0,i])\n",
    "    n.color='red'\n",
    "    s.append(n)\n",
    "    \n",
    "print('after green ', len(s.notes))\n",
    "s.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict one song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thresh = 0.8\n",
    "\n",
    "# create a seed and predict stuff\n",
    "t = random.randint(0,nn_inout2.shape[0]-1)\n",
    "seed = nn_inout2[t:t+1,:,:]\n",
    "print('seed size : ', seed.shape)\n",
    "\n",
    "inp = seed\n",
    "# inp.shape\n",
    "# inp[:,-lookback:,:].shape\n",
    "for i in range(128):\n",
    "    p = model.predict(inp[:,-lookback:,:])\n",
    "\n",
    "    p = cleanpred(p[0, -1])\n",
    "    inp = np.concatenate([inp,p[newaxis,newaxis,:]], axis=1)\n",
    "    print('.', end='')\n",
    "    \n",
    "print('Total size ', inp.shape)    \n",
    "s = stream.Stream()\n",
    "for i in range(len(inp[0])):\n",
    "    n = predbitfieldtonote(inp[0,i],threshold=thresh)\n",
    "    if i < lookback:\n",
    "        n.color='blue'\n",
    "    s.append(n)\n",
    "s.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write predicted song to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writePrediction(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: Convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(lookback,nn_inout.shape[1],))\n",
    "x = Conv1D(64,1, strides=2)(inp)\n",
    "x = Conv1D(128,1, strides=2)(inp)\n",
    "\n",
    "x = LSTM(256, return_sequences=True)(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = LSTM(256)(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(nn_inout.shape[1])(x)\n",
    "a1 = Activation('sigmoid')(Lambda(lambda z : z[:,:n_vocab])(x)) # notes\n",
    "a2 = Activation('softmax')(Lambda(lambda z : z[:,n_vocab:])(x)) # duration\n",
    "x= concatenate([a1,a2])\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "\n",
    "# model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001))\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spotify architecture (winner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(lookback,nn_inout.shape[1],))\n",
    "x = Conv1D(128,4, strides=2, activation='relu')(inp)\n",
    "\n",
    "x = Dropout(0.4)(x)\n",
    "x = Conv1D(128,1, strides=2, activation='relu')(x)\n",
    "\n",
    "\n",
    "x = LSTM(512, return_sequences=True)(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = LSTM(256)(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(nn_inout.shape[1])(x)\n",
    "a1 = Activation('sigmoid')(Lambda(lambda z : z[:,:n_vocab])(x)) # notes\n",
    "a2 = Activation('softmax')(Lambda(lambda z : z[:,n_vocab:])(x)) # duration\n",
    "x= concatenate([a1,a2])\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "\n",
    "# learning_rate = 0.1\n",
    "# sgd = SGD(lr=learning_rate)\n",
    "\n",
    "# model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001))\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop')\n",
    "# model.compile(loss='binary_crossentropy', optimizer=sgd)\n",
    "# model.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# inp = Input(shape=(lookback,nn_inout.shape[1],))\n",
    "# x = Conv1D(144,1, strides=2, activation='relu')(inp)\n",
    "# # x = MaxPooling1D(strides=2)(x)\n",
    "# # x = MaxPooling1D(strides=2)(x)\n",
    "# # x = MaxPooling1D(strides=2)(x)\n",
    "# # x = MaxPooling1D(strides=2)(x)\n",
    "# x = Dropout(0.3)(x)\n",
    "# x = Conv1D(144,1, strides=2, activation='relu')(x)\n",
    "# x = MaxPooling1D(strides=1)(x)\n",
    "# x = MaxPooling1D(strides=1)(x)\n",
    "# x = LSTM(256, return_sequences=True)(x)\n",
    "# x = Dropout(0.4)(x)\n",
    "# x = LSTM(512, return_sequences=True)(x)\n",
    "# x = Dropout(0.3)(x)\n",
    "# x = LSTM(256)(x)\n",
    "# x = Dropout(0.3)(x)\n",
    "# x = Dense(nn_inout.shape[1])(x)\n",
    "# a1 = Activation('sigmoid')(Lambda(lambda z : z[:,:n_vocab])(x)) # notes\n",
    "# a2 = Activation('softmax')(Lambda(lambda z : z[:,n_vocab:])(x)) # duration\n",
    "# x= concatenate([a1,a2])\n",
    "# model = Model(inputs=inp, outputs=x)\n",
    "\n",
    "\n",
    "# model.compile(loss='binary_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('all data', nn_inout.shape)\n",
    "print('lookback', lookback)\n",
    "print('train', nn_inout[:-lookback].shape)\n",
    "print('to predict', nn_inout[lookback:].shape)\n",
    "\n",
    "# Add '0' at the end to make sure it fits blocks of 32\n",
    "nn_inout2 = np.pad(nn_inout,((0,lookback-nn_inout.shape[0]%lookback),(0,0)), 'constant', constant_values=(0))\n",
    "nn_inout2.shape\n",
    "nn_inout2 = nn_inout2.reshape(-1, lookback, 144)\n",
    "nn_inout2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "basicLossPlot = PlotLosses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(nn_inout2[:-1,:,:], nn_inout2[1:,0,:], epochs=1000, batch_size=512, callbacks=[basicLossPlot])\n",
    "model.save_weights('weights-improvement-p3{datetime.now().strftime(\"%Y%m%d%H%M%S\")}.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = random.randint(1,nn_inout2.shape[0])\n",
    "# t\n",
    "s = predtostream(nn_inout2[t]) # stream of 32 notes\n",
    "# s\n",
    "\n",
    "n = predbitfieldtonote(model.predict(nn_inout2[t:t+1,:,:])[0])\n",
    "n.color='red'\n",
    "s.append(n)\n",
    "c = predbitfieldtonote(nn_inout2[t+1,0,:])\n",
    "c.color='green'\n",
    "s.append(c)\n",
    "s.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.8\n",
    "\n",
    "# create a seed and predict stuff\n",
    "t = random.randint(0,nn_inout2.shape[0]-1)\n",
    "seed = nn_inout2[t:t+1,:,:]\n",
    "print('seed size : ', seed.shape)\n",
    "\n",
    "inp = seed\n",
    "# inp.shape\n",
    "# inp[:,-lookback:,:].shape\n",
    "for i in range(150):\n",
    "    p = model.predict(inp[:,-lookback:,:])\n",
    "\n",
    "    p = cleanpred(p[0])\n",
    "    inp = np.concatenate([inp,p[newaxis,newaxis,:]], axis=1)\n",
    "    print('.', end='')\n",
    "    \n",
    "print('Total size ', inp.shape)    \n",
    "s = stream.Stream()\n",
    "for i in range(len(inp[0])):\n",
    "    n = predbitfieldtonote(inp[0,i],threshold=thresh)\n",
    "    if i < lookback:\n",
    "        n.color='blue'\n",
    "    s.append(n)\n",
    "s.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writePrediction(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import IPython\n",
    "# IPython.display.display(IPython.display.Audio(url=\"output/test_output20180309231423.mid\"))\n",
    "# ipd.Audio('output/test_output20180309231423.mid') # load a local WAV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fully connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inp = Input(shape=(lookback,nn_inout.shape[1],))\n",
    "x = LSTM(256, return_sequences=True)(inp)\n",
    "x = Dropout(0.3)(x)\n",
    "x = LSTM(512, return_sequences=True)(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = LSTM(256)(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(nn_inout.shape[1])(x)\n",
    "a1 = Activation('sigmoid')(Lambda(lambda z : z[:,:n_vocab])(x)) # notes\n",
    "a2 = Activation('softmax')(Lambda(lambda z : z[:,n_vocab:])(x)) # duration\n",
    "x= concatenate([a1,a2])\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('all data', nn_inout.shape)\n",
    "print('lookback', lookback)\n",
    "print('train', nn_inout[:-lookback].shape)\n",
    "print('to predict', nn_inout[lookback:].shape)\n",
    "\n",
    "# Add '0' at the end to make sure it fits blocks of 32\n",
    "nn_inout2 = np.pad(nn_inout,((0,lookback-nn_inout.shape[0]%lookback),(0,0)), 'constant', constant_values=(0))\n",
    "nn_inout2.shape\n",
    "nn_inout2 = nn_inout2.reshape(-1, lookback, 144)\n",
    "nn_inout2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "basicLossPlot = PlotLosses()\n",
    "model.fit(nn_inout2[:-1,:,:], nn_inout2[1:,0,:], epochs=200, batch_size=512, callbacks=[basicLossPlot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thresh = 0.8\n",
    "\n",
    "# create a seed and predict stuff\n",
    "t = random.randint(0,nn_inout2.shape[0]-1)\n",
    "seed = nn_inout2[t:t+1,:,:]\n",
    "print('seed size : ', seed.shape)\n",
    "\n",
    "inp = seed\n",
    "# inp.shape\n",
    "# inp[:,-lookback:,:].shape\n",
    "for i in range(100):\n",
    "    p = model.predict(inp[:,-lookback:,:])\n",
    "\n",
    "    p = cleanpred(p[0])\n",
    "    inp = np.concatenate([inp,p[newaxis,newaxis,:]], axis=1)\n",
    "    print('.', end='')\n",
    "    \n",
    "print('Total size ', inp.shape)    \n",
    "s = stream.Stream()\n",
    "for i in range(len(inp[0])):\n",
    "    n = predbitfieldtonote(inp[0,i],threshold=thresh)\n",
    "    if i < lookback:\n",
    "        n.color='blue'\n",
    "    s.append(n)\n",
    "s.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Time distribution model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# inp = Input(shape=(lookback,nn_inout.shape[1],))\n",
    "# x = TimeDistributed(Dense(nn_inout.shape[1]))(inp)\n",
    "# x = LSTM(256, return_sequences=True)(x)\n",
    "# x = Dropout(0.3)(x)\n",
    "\n",
    "# x = TimeDistributed(Dense(nn_inout.shape[1]))(x)\n",
    "# x = LSTM(256)(x)\n",
    "# x = Dropout(0.3)(x)\n",
    "# x = Dense(nn_inout.shape[1])(x)\n",
    "# a1 = Activation('sigmoid')(Lambda(lambda z : z[:,:n_vocab])(x)) # notes\n",
    "# a2 = Activation('softmax')(Lambda(lambda z : z[:,n_vocab:])(x)) # duration\n",
    "# x= concatenate([a1,a2])\n",
    "# model = Model(inputs=inp, outputs=x)\n",
    "\n",
    "# # model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001))\n",
    "# model.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
    "# model.summary()\n",
    "\n",
    "\n",
    "inp = Input(shape=(lookback,nn_inout.shape[1],))\n",
    "x = TimeDistributed(Dense(nn_inout.shape[1]))(inp)\n",
    "x = LSTM(256, return_sequences=True)(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = TimeDistributed(Dense(nn_inout.shape[1]))(x)\n",
    "x = LSTM(256)(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(nn_inout.shape[1])(x)\n",
    "a1 = Activation('sigmoid')(Lambda(lambda z : z[:,:n_vocab])(x)) # notes\n",
    "a2 = Activation('softmax')(Lambda(lambda z : z[:,n_vocab:])(x)) # duration\n",
    "x= concatenate([a1,a2])\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "\n",
    "# model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001))\n",
    "model.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('all data', nn_inout.shape)\n",
    "print('lookback', lookback)\n",
    "print('train', nn_inout[:-lookback].shape)\n",
    "print('to predict', nn_inout[lookback:].shape)\n",
    "\n",
    "# Add '0' at the end to make sure it fits blocks of 32\n",
    "nn_inout2 = np.pad(nn_inout,((0,lookback-nn_inout.shape[0]%lookback),(0,0)), 'constant', constant_values=(0))\n",
    "nn_inout2.shape\n",
    "nn_inout2 = nn_inout2.reshape(-1, lookback, 144)\n",
    "nn_inout2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "basicLossPlot = PlotLosses()\n",
    "model.fit(nn_inout2[:-1,:,:], nn_inout2[1:,0,:], epochs=200, batch_size=512, callbacks=[basicLossPlot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thresh = 0.8\n",
    "\n",
    "# create a seed and predict stuff\n",
    "t = random.randint(0,nn_inout2.shape[0]-1)\n",
    "seed = nn_inout2[t:t+1,:,:]\n",
    "print('seed size : ', seed.shape)\n",
    "\n",
    "inp = seed\n",
    "# inp.shape\n",
    "# inp[:,-lookback:,:].shape\n",
    "for i in range(128):\n",
    "    p = model.predict(inp[:,-lookback:,:])\n",
    "    p = cleanpred(p[0])\n",
    "    inp = np.concatenate([inp,p[newaxis,newaxis,:]], axis=1)\n",
    "    print('.', end='')\n",
    "    \n",
    "print('Total size ', inp.shape)    \n",
    "s = stream.Stream()\n",
    "for i in range(len(inp[0])):\n",
    "    n = predbitfieldtonote(inp[0,i],threshold=thresh)\n",
    "    if i < lookback:\n",
    "        n.color='blue'\n",
    "    s.append(n)\n",
    "s.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writePrediction(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = Input(shape=(lookback,nn_inout.shape[1],))\n",
    "x = BatchNormalization()(inp)\n",
    "# x = Conv2D(64, (4, 4), border_mode='valid')(x)\n",
    "# x = LSTM(256, return_sequences=True)(inp)\n",
    "# x = Dropout(0.3)(x)\n",
    "# x = LSTM(512, return_sequences=True)(x)\n",
    "# x = Dropout(0.3)(x)\n",
    "# x = LSTM(256)(x)\n",
    "# x = Dropout(0.3)(x)\n",
    "# x = Dense(nn_inout.shape[1])(x)\n",
    "# a1 = Activation('sigmoid')(Lambda(lambda z : z[:,:n_vocab])(x)) # notes\n",
    "# a2 = Activation('softmax')(Lambda(lambda z : z[:,n_vocab:])(x)) # duration\n",
    "# x= concatenate([a1,a2])\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "\n",
    "# model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001))\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop')\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "# # Input block\n",
    "# x = ZeroPadding2D(padding=(0, 37))(melgram_input)\n",
    "# x = BatchNormalization(axis=freq_axis, name='bn_0_freq')(x)\n",
    "\n",
    "# # Conv block 1\n",
    "# x = Convolution2D(64, 3, 3, border_mode='same', name='conv1')(x)\n",
    "# x = BatchNormalization(axis=channel_axis, mode=0, name='bn1')(x)\n",
    "# x = ELU()(x)\n",
    "# x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='pool1')(x)\n",
    "# x = Dropout(0.1, name='dropout1')(x)\n",
    "\n",
    "# # Conv block 2\n",
    "# x = Convolution2D(128, 3, 3, border_mode='same', name='conv2')(x)\n",
    "# x = BatchNormalization(axis=channel_axis, mode=0, name='bn2')(x)\n",
    "# x = ELU()(x)\n",
    "# x = MaxPooling2D(pool_size=(3, 3), strides=(3, 3), name='pool2')(x)\n",
    "# x = Dropout(0.1, name='dropout2')(x)\n",
    "\n",
    "# # Conv block 3\n",
    "# x = Convolution2D(128, 3, 3, border_mode='same', name='conv3')(x)\n",
    "# x = BatchNormalization(axis=channel_axis, mode=0, name='bn3')(x)\n",
    "# x = ELU()(x)\n",
    "# x = MaxPooling2D(pool_size=(4, 4), strides=(4, 4), name='pool3')(x)\n",
    "# x = Dropout(0.1, name='dropout3')(x)\n",
    "\n",
    "# # Conv block 4\n",
    "# x = Convolution2D(128, 3, 3, border_mode='same', name='conv4')(x)\n",
    "# x = BatchNormalization(axis=channel_axis, mode=0, name='bn4')(x)\n",
    "# x = ELU()(x)\n",
    "# x = MaxPooling2D(pool_size=(4, 4), strides=(4, 4), name='pool4')(x)\n",
    "# x = Dropout(0.1, name='dropout4')(x)\n",
    "\n",
    "# # reshaping\n",
    "# if K.image_dim_ordering() == 'th':\n",
    "#     x = Permute((3, 1, 2))(x)\n",
    "# x = Reshape((15, 128))(x)\n",
    "\n",
    "# # GRU block 1, 2, output\n",
    "# x = GRU(32, return_sequences=True, name='gru1')(x)\n",
    "# x = GRU(32, return_sequences=False, name='gru2')(x)\n",
    "# x = Dropout(0.3)(x)\n",
    "# if include_top:\n",
    "#     x = Dense(50, activation='sigmoid', name='output')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
